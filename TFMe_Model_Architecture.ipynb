{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSize = 305 # Only LiDAR features\n",
    "npy_features = np.load('dataset.npy')\n",
    "\n",
    "# Temporal split for the dataset\n",
    "train_raw = npy_features[:50335,:dataSize]\n",
    "val_raw = npy_features[50335:60341,:dataSize]\n",
    "test_raw = npy_features[60341:,:dataSize]\n",
    "print(train_raw.shape, val_raw.shape, test_raw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape all datasets to shape (-1, 5, 61)\n",
    "TIMESTEPS = 5\n",
    "FEATURES = 61\n",
    "X_train = train_raw.reshape(-1, TIMESTEPS, FEATURES)\n",
    "X_val = val_raw.reshape(-1, TIMESTEPS, FEATURES)\n",
    "X_test = test_raw.reshape(-1, TIMESTEPS, FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling the features using MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(train_raw.reshape(-1, dataSize)).reshape(train_raw.shape)\n",
    "X_test = scaler.transform(test_raw.reshape(-1, dataSize)).reshape(test_raw.shape)\n",
    "X_val = scaler.transform(val_raw.reshape(-1, dataSize)).reshape(val_raw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape all datasets to shape (-1, TIMESTEPS, FEATURES)\n",
    "X_train = X_train.reshape(-1, TIMESTEPS, FEATURES)\n",
    "X_val = X_val.reshape(-1, TIMESTEPS, FEATURES)\n",
    "X_test = X_test.reshape(-1, TIMESTEPS, FEATURES)\n",
    "\n",
    "print(X_train.shape, X_val.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFMe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "N_LAYERS = 4\n",
    "D_MODEL = 128\n",
    "N_HEAD = 8\n",
    "FFN = 512\n",
    "MAX_LENGTH = 10\n",
    "BATCH_SIZE = 256\n",
    "EPOCHS = 500\n",
    "LEARNING_RATE = 1e-4\n",
    "MEMORY_SLOTS = 250\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Reconstruction loss\n",
    "criterion = lambda recon, target: nn.functional.mse_loss(recon, target)\n",
    "\n",
    "# Early stopping implementation\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, min_delta=1e-4, restore_best_weights=True):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.restore_best_weights = restore_best_weights\n",
    "        self.best_model = None\n",
    "        self.best_loss = None\n",
    "        self.counter = 0\n",
    "        self.status = \"\"\n",
    "\n",
    "    def __call__(self, model, val_loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "            self.best_model = copy.deepcopy(model.state_dict())\n",
    "        elif val_loss > self.best_loss - self.min_delta:\n",
    "            self.counter += 1\n",
    "            self.status = f\"No improvement in the last {self.counter} epochs.\"\n",
    "            if self.counter >= self.patience:\n",
    "                self.status = f\"Early stopping triggered after {self.counter} epochs.\"\n",
    "                if self.restore_best_weights:\n",
    "                    model.load_state_dict(self.best_model)\n",
    "                return True\n",
    "        else:\n",
    "            self.best_loss = val_loss\n",
    "            self.best_model = copy.deepcopy(model.state_dict())\n",
    "            self.counter = 0\n",
    "            self.status = f\"Improvement found, counter reset.\"\n",
    "        return False\n",
    "    \n",
    "# Positional Encoding for the Transformer\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super().__init__()\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-np.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Memory Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MultiHeadMemory(nn.Module):\n",
    "    def __init__(self, mem_dim, fea_dim, n_heads=4, shrink_thres=0.0025):\n",
    "        super().__init__()\n",
    "        self.n_heads = n_heads\n",
    "        self.mem_dim = mem_dim\n",
    "        self.fea_dim = fea_dim\n",
    "        self.head_dim = fea_dim // n_heads\n",
    "        \n",
    "        # Threshold lambda is typically [1/N, 3/N]\n",
    "        self.shrink_thres = shrink_thres \n",
    "\n",
    "        assert fea_dim % n_heads == 0, \"Feature dimension must be divisible by n_heads\"\n",
    "\n",
    "        self.memory = nn.Parameter(torch.Tensor(n_heads, mem_dim, self.head_dim))\n",
    "        nn.init.kaiming_uniform_(self.memory)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: [batch_size, timesteps, fea_dim]\n",
    "        \"\"\"\n",
    "        b, t, d = x.shape\n",
    "        \n",
    "        # 1. Reshape Input\n",
    "        x = x.view(b, t, self.n_heads, self.head_dim).transpose(1, 2)\n",
    "        x = x.reshape(b * t, self.n_heads, self.head_dim)\n",
    "        \n",
    "        # 2. Normalize (Cosine Similarity)\n",
    "        x_norm = F.normalize(x, dim=2) \n",
    "        mem_norm = F.normalize(self.memory, dim=2) \n",
    "        \n",
    "        # 3. Calculate Similarity\n",
    "        att_weight = torch.einsum('bhd,hmd->bhm', x_norm, mem_norm)\n",
    "        \n",
    "        # 4. Softmax\n",
    "        att_weight = F.softmax(att_weight, dim=2)\n",
    "        \n",
    "        # 5. Hard Shrinkage\n",
    "        if self.shrink_thres > 0:\n",
    "            w_minus_lambda = att_weight - self.shrink_thres\n",
    "            mask = F.relu(w_minus_lambda)\n",
    "            att_weight = (mask * att_weight) / (torch.abs(w_minus_lambda) + 1e-12)\n",
    "\n",
    "            # Re-normalize so weights sum to 1 \n",
    "            att_weight = att_weight / (att_weight.sum(dim=2, keepdim=True) + 1e-12)\n",
    "\n",
    "        # 6. Reconstruct\n",
    "        out = torch.einsum('bhm,hmd->bhd', att_weight, self.memory)\n",
    "        \n",
    "        # 7. Reshape back\n",
    "        out = out.view(b, t, self.n_heads, self.head_dim)\n",
    "        out = out.transpose(1, 2).contiguous()\n",
    "        out = out.view(b, t, d)\n",
    "        \n",
    "        return out, att_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeBranch(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_features=FEATURES, \n",
    "                 timesteps=TIMESTEPS,\n",
    "                 d_model=D_MODEL,\n",
    "                 nhead=N_HEAD,\n",
    "                 dim_feedforward=FFN,\n",
    "                 num_layers=N_LAYERS,\n",
    "                 dropout=0.1,\n",
    "                 mem_dim=MEMORY_SLOTS,\n",
    "                 max_length=MAX_LENGTH):\n",
    "        super().__init__()\n",
    "        self.timesteps = timesteps\n",
    "        self.input_features = input_features\n",
    "        self.d_model = d_model\n",
    "        self.input_embedding = nn.Linear(input_features, d_model)\n",
    "        self.positional_encoding = PositionalEncoding(d_model, max_len=max_length)\n",
    "        \n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, \n",
    "            nhead=nhead, \n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        \n",
    "        # --- ADDED MEMORY MODULE ---\n",
    "        self.memory_layer = MultiHeadMemory(mem_dim=mem_dim, fea_dim=d_model, n_heads=nhead, shrink_thres=1/mem_dim)\n",
    "                \n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model * 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(d_model * 2, input_features)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # 1. Input Embedding\n",
    "        x = self.input_embedding(x) \n",
    "        x = x * np.sqrt(self.d_model)\n",
    "        x = x.permute(1, 0, 2)\n",
    "        \n",
    "        # 2. Add Positional Encoding\n",
    "        x = self.positional_encoding(x)\n",
    "        \n",
    "        # 3. Transformer Encoder\n",
    "        enc_out = self.transformer_encoder(x)\n",
    "        enc_out = enc_out.permute(1, 0, 2)\n",
    "        \n",
    "        # 4. Memory Module\n",
    "        # We pass the encoder output into the memory module.\n",
    "        # 'z_hat' is the reconstructed latent vector (clean).\n",
    "        # 'att' contains the weights (needed for loss function).\n",
    "        z_hat, att = self.memory_layer(enc_out)\n",
    "        \n",
    "        # 5. Final Output Reconstruction\n",
    "        recon = self.output_layer(z_hat)\n",
    "        \n",
    "        return recon, att"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frequency Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectralBranch(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_features=FEATURES,\n",
    "                 d_model=D_MODEL,\n",
    "                 timesteps=TIMESTEPS,\n",
    "                 nhead=N_HEAD,\n",
    "                 num_layers=N_LAYERS,\n",
    "                 mem_dim=MEMORY_SLOTS,\n",
    "                 ffn=FFN):\n",
    "        super().__init__()\n",
    "        self.freq_bins = (timesteps // 2) + 1\n",
    "        self.freq_input_dim = input_features * 2 # Real + Imag\n",
    "        \n",
    "        self.embedding = nn.Linear(self.freq_input_dim, d_model)\n",
    "        self.pos_encoder = PositionalEncoding(d_model, max_len=self.freq_bins + 10)\n",
    "\n",
    "        encoder_layers = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, \n",
    "            nhead=nhead, \n",
    "            dim_feedforward=ffn, \n",
    "            dropout=0.1,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers=num_layers)\n",
    "        \n",
    "        # --- ADDED MEMORY MODULE ---\n",
    "        self.freq_memory = MultiHeadMemory(mem_dim=mem_dim, fea_dim=d_model, n_heads=nhead, shrink_thres=1/mem_dim)\n",
    "\n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model * 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(d_model * 2, self.freq_input_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # 1. FFT\n",
    "        x_fft = torch.fft.rfft(x, dim=1) \n",
    "        x_spectral = torch.cat([x_fft.real, x_fft.imag], dim=-1)\n",
    "        \n",
    "        # 2. Embed & Position\n",
    "        x_emb = self.embedding(x_spectral)\n",
    "        x_emb = x_emb.permute(1, 0, 2)\n",
    "        x_emb = self.pos_encoder(x_emb)\n",
    "        x_emb = x_emb.permute(1, 0, 2)\n",
    "        \n",
    "        # 3. Transformer Encoder\n",
    "        enc_out = self.transformer_encoder(x_emb)\n",
    "        \n",
    "        # 4. Memory Module\n",
    "        mem_out, att = self.freq_memory(enc_out)\n",
    "        \n",
    "        # 5. Reconstruct\n",
    "        recon_spectral = self.output_layer(mem_out)\n",
    "        \n",
    "        # 6. Inverse FFT\n",
    "        real, imag = torch.chunk(recon_spectral, 2, dim=-1)\n",
    "        recon_complex = torch.complex(real, imag)\n",
    "        recon_time = torch.fft.irfft(recon_complex, n=x.size(1), dim=1)\n",
    "        \n",
    "        return recon_time, att"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dual Domain Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DualDomainTransformer(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_features=FEATURES, \n",
    "                 timesteps=TIMESTEPS,\n",
    "                 d_model=D_MODEL,\n",
    "                 nhead=N_HEAD,\n",
    "                 dim_feedforward=FFN,\n",
    "                 num_layers=N_LAYERS,\n",
    "                 mem_dim=MEMORY_SLOTS):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Branch 1: Time Domain \n",
    "        self.time_branch = TimeBranch(\n",
    "        input_features=input_features,\n",
    "        timesteps=timesteps,\n",
    "        d_model=d_model,\n",
    "        nhead=nhead,\n",
    "        dim_feedforward=dim_feedforward,\n",
    "        num_layers=num_layers,\n",
    "        mem_dim=mem_dim\n",
    "    )\n",
    "        \n",
    "        # Branch 2: Frequency Domain \n",
    "        self.spectral_branch = SpectralBranch(\n",
    "            input_features=input_features,\n",
    "            d_model=d_model,\n",
    "            timesteps=timesteps,\n",
    "            nhead=nhead,\n",
    "            num_layers=num_layers,\n",
    "            ffn=dim_feedforward,\n",
    "            mem_dim=mem_dim\n",
    "        )\n",
    "    def forward(self, x):\n",
    "\n",
    "        # 1. Get Time Domain Reconstruction and Attention\n",
    "        time_recon, time_att = self.time_branch(x)\n",
    "        \n",
    "        # 2. Get Frequency Domain Reconstruction (Projected back to Time)\n",
    "        freq_recon, freq_att = self.spectral_branch(x)\n",
    "        \n",
    "        return time_recon, freq_recon, time_att, freq_att"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DualDomainTransformer()\n",
    "model.load_state_dict(torch.load(\"best.pth\", map_location=DEVICE))\n",
    "model.to(DEVICE)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect anomalies based on the 3-sigma threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_anomalies(model, data_loader):\n",
    "    anomalies_found = 0\n",
    "    is_time_anomaly_count = 0\n",
    "    is_freq_anomaly_count = 0   \n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            inputs = batch[0].to(DEVICE)\n",
    "            time_recon, freq_recon, _, _ = model(inputs)\n",
    "            \n",
    "            loss_time = torch.mean(torch.square(inputs - time_recon), dim=(1, 2))\n",
    "            loss_freq = torch.mean(torch.square(inputs - freq_recon), dim=(1, 2))\n",
    "            \n",
    "            is_time_anomaly = loss_time > 0.007686922559514642\n",
    "            is_freq_anomaly = loss_freq > 0.005322358105331659\n",
    "\n",
    "            is_time_anomaly_count += is_time_anomaly.sum().item()\n",
    "            is_freq_anomaly_count += is_freq_anomaly.sum().item()\n",
    "            \n",
    "            is_anomaly = torch.logical_or(is_time_anomaly, is_freq_anomaly)\n",
    "            \n",
    "            batch_anomalies = is_anomaly.sum().item()\n",
    "            anomalies_found += batch_anomalies\n",
    "            \n",
    "    return anomalies_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "test_loader = DataLoader(TensorDataset(test_tensor), batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "false_positive = detect_anomalies(model, test_loader)\n",
    "true_negative = len(X_test) - false_positive\n",
    "print(f\"False Positive: {false_positive}, True Negative: {true_negative}\")\n",
    "print(\"All Samples:\", len(X_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TRANSFORMERS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
